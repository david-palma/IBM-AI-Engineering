# Scalable Machine Learning on Big Data using Apache Spark

In this project is required to write Python code on a iPython Notebook into Watson Studio or a personal jupyter/pyspark environment in order to solve a classification problem on big data using Apache Spark.

**Note:**
Apache Spark is an open source framework that leverages cluster computing and distributed storage to process extremely large data sets in an efficient and cost effective manner. Therefore an applied knowledge of working with Apache Spark is a great asset and potential differentiator for a Machine Learning engineer.
